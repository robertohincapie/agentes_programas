{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6481c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "import json\n",
    "from estado import AgentState\n",
    "from estado import Nivel\n",
    "from typing import Dict, Any, List\n",
    "from langchain_core.tools import tool\n",
    "import os\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb8788f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def _dedupe_urls(urls: List[str]) -> List[str]:\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for u in urls:\n",
    "        if u and u not in seen:\n",
    "            seen.add(u)\n",
    "            out.append(u)\n",
    "    return out\n",
    "\n",
    "def _normalize_result(results: List[Dict[str, Any]], max_urls: int = 8) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    results: [{\"url\": \"...\", \"title\": \"...\", \"snippet\": \"...\"}]\n",
    "    \"\"\"\n",
    "    urls = _dedupe_urls([r.get(\"url\") for r in results if r.get(\"url\")])\n",
    "    return {\n",
    "        \"urls\": urls[:max_urls],\n",
    "        \"results\": results[:max_urls],\n",
    "        \"count\": min(len(urls), max_urls),\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Tool 1: Tavily\n",
    "# -----------------------------\n",
    "@tool(\"tavily_search_urls\")\n",
    "def tavily_search_urls(query: str, max_results: int = 8) -> str:\n",
    "    \"\"\"\n",
    "    Busca en Tavily y retorna URLs útiles como JSON string.\n",
    "    Requiere TAVILY_API_KEY en env.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from tavily import TavilyClient\n",
    "        api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "        if not api_key:\n",
    "            return json.dumps({\"error\": \"Missing TAVILY_API_KEY\", \"urls\": [], \"results\": [], \"count\": 0})\n",
    "\n",
    "        client = TavilyClient(api_key=api_key)\n",
    "        resp = client.search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            include_answer=False,\n",
    "            include_raw_content=False,\n",
    "            include_images=False,\n",
    "        )\n",
    "        items = resp.get(\"results\", []) or []\n",
    "        results = [{\"url\": it.get(\"url\"), \"title\": it.get(\"title\"), \"snippet\": it.get(\"content\")} for it in items]\n",
    "        return json.dumps(_normalize_result(results, max_urls=max_results), ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Tavily failed: {e}\", \"urls\": [], \"results\": [], \"count\": 0})\n",
    "\n",
    "# -----------------------------\n",
    "# Tool 2: OpenAI \"web search\"\n",
    "# -----------------------------\n",
    "@tool(\"openai_websearch_urls\")\n",
    "def openai_websearch_urls(query: str, max_results: int = 8) -> str:\n",
    "    \"\"\"\n",
    "    Hace web search con OpenAI (requiere modelo/feature con web search habilitado).\n",
    "    Retorna URLs como JSON string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\")  # ajusta tu modelo\n",
    "        # LangChain no estandariza 100% la salida de \"web search\" entre versiones.\n",
    "        # Patrón robusto: pedirle al modelo SOLO JSON con urls y títulos a partir de búsqueda.\n",
    "        prompt = f\"\"\"\n",
    "Necesito que uses navegación web para buscar: {query}\n",
    "Devuélveme SOLO un JSON con este formato exacto:\n",
    "{{\n",
    "  \"results\": [{{\"url\": \"...\", \"title\": \"...\", \"snippet\": \"...\"}}],\n",
    "  \"urls\": [\"...\"]\n",
    "}}\n",
    "Incluye máximo {max_results} resultados. No agregues texto adicional.\n",
    "\"\"\"\n",
    "        resp = llm.invoke(prompt)\n",
    "        text = resp.content.strip()\n",
    "\n",
    "        # intenta parsear JSON directo\n",
    "        data = json.loads(text)\n",
    "        results = data.get(\"results\", []) or []\n",
    "        # si no viene urls, construirlas desde results\n",
    "        if not data.get(\"urls\"):\n",
    "            data[\"urls\"] = [r.get(\"url\") for r in results if r.get(\"url\")]\n",
    "        data[\"urls\"] = _dedupe_urls(data[\"urls\"])[:max_results]\n",
    "        data[\"results\"] = results[:max_results]\n",
    "        data[\"count\"] = len(data[\"urls\"])\n",
    "        return json.dumps(data, ensure_ascii=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"OpenAI websearch failed: {e}\", \"urls\": [], \"results\": [], \"count\": 0})\n",
    "\n",
    "# -----------------------------\n",
    "# Tool 3A: Google Custom Search JSON API\n",
    "# -----------------------------\n",
    "@tool(\"google_cse_search_urls\")\n",
    "def google_cse_search_urls(query: str, max_results: int = 8) -> str:\n",
    "    \"\"\"\n",
    "    Google Custom Search JSON API.\n",
    "    Requiere GOOGLE_API_KEY y GOOGLE_CSE_ID.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        cse_id = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "        if not api_key or not cse_id:\n",
    "            return json.dumps({\"error\": \"Missing GOOGLE_API_KEY or GOOGLE_CSE_ID\", \"urls\": [], \"results\": [], \"count\": 0})\n",
    "\n",
    "        url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "        params = {\"key\": api_key, \"cx\": cse_id, \"q\": query, \"num\": min(max_results, 10)}\n",
    "        r = requests.get(url, params=params, timeout=20)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "\n",
    "        items = data.get(\"items\", []) or []\n",
    "        results = [{\"url\": it.get(\"link\"), \"title\": it.get(\"title\"), \"snippet\": it.get(\"snippet\")} for it in items]\n",
    "        return json.dumps(_normalize_result(results, max_urls=max_results), ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Google CSE failed: {e}\", \"urls\": [], \"results\": [], \"count\": 0})\n",
    "\n",
    "# -----------------------------\n",
    "# Tool 3B (alternativa): SerpAPI\n",
    "# -----------------------------\n",
    "@tool(\"serpapi_search_urls\")\n",
    "def serpapi_search_urls(query: str, max_results: int = 8) -> str:\n",
    "    \"\"\"\n",
    "    Alternativa: SerpAPI.\n",
    "    Requiere SERPAPI_API_KEY.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "        if not api_key:\n",
    "            return json.dumps({\"error\": \"Missing SERPAPI_API_KEY\", \"urls\": [], \"results\": [], \"count\": 0})\n",
    "\n",
    "        url = \"https://serpapi.com/search.json\"\n",
    "        params = {\"engine\": \"google\", \"q\": query, \"api_key\": api_key, \"num\": max_results}\n",
    "        r = requests.get(url, params=params, timeout=20)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "\n",
    "        organic = data.get(\"organic_results\", []) or []\n",
    "        results = [{\"url\": it.get(\"link\"), \"title\": it.get(\"title\"), \"snippet\": it.get(\"snippet\")} for it in organic]\n",
    "        return json.dumps(_normalize_result(results, max_urls=max_results), ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"SerpAPI failed: {e}\", \"urls\": [], \"results\": [], \"count\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c4ba5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool(\"web_search_urls_fallback\")\n",
    "def web_search_urls_fallback(query: str, max_results: int = 8) -> str:\n",
    "    \"\"\"\n",
    "    Intenta Tavily -> OpenAI Web Search -> Google (CSE o SerpAPI),\n",
    "    y retorna URLs en JSON.\n",
    "    \"\"\"\n",
    "    # 1) Tavily\n",
    "    t = json.loads(tavily_search_urls.invoke({\"query\": query, \"max_results\": max_results}))\n",
    "    if t.get(\"urls\"):\n",
    "        t[\"provider\"] = \"tavily\"\n",
    "        return json.dumps(t, ensure_ascii=False)\n",
    "\n",
    "    # 2) OpenAI web search\n",
    "    o = json.loads(openai_websearch_urls.invoke({\"query\": query, \"max_results\": max_results}))\n",
    "    if o.get(\"urls\"):\n",
    "        o[\"provider\"] = \"openai_websearch\"\n",
    "        return json.dumps(o, ensure_ascii=False)\n",
    "\n",
    "    # 3) Google (elige UNA de estas dos)\n",
    "    g = json.loads(google_cse_search_urls.invoke({\"query\": query, \"max_results\": max_results}))\n",
    "    if g.get(\"urls\"):\n",
    "        g[\"provider\"] = \"google_cse\"\n",
    "        return json.dumps(g, ensure_ascii=False)\n",
    "\n",
    "    # Si usas SerpAPI, cambia lo anterior por:\n",
    "    # g = json.loads(serpapi_search_urls.invoke({\"query\": query, \"max_results\": max_results}))\n",
    "    # if g.get(\"urls\"):\n",
    "    #     g[\"provider\"] = \"serpapi\"\n",
    "    #     return json.dumps(g, ensure_ascii=False)\n",
    "\n",
    "    # Nada funcionó\n",
    "    return json.dumps({\n",
    "        \"provider\": None,\n",
    "        \"urls\": [],\n",
    "        \"results\": [],\n",
    "        \"count\": 0,\n",
    "        \"errors\": {\n",
    "            \"tavily\": t.get(\"error\"),\n",
    "            \"openai_websearch\": o.get(\"error\"),\n",
    "            \"google\": g.get(\"error\"),\n",
    "        }\n",
    "    }, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28764bed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_tool_calling_agent' from 'langchain.agents' (c:\\Users\\000010478\\Downloads\\agentes_programas\\.venv\\Lib\\site-packages\\langchain\\agents\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_tool_calling_agent, AgentExecutor\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[32m      5\u001b[39m llm = ChatOpenAI(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, temperature=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'create_tool_calling_agent' from 'langchain.agents' (c:\\Users\\000010478\\Downloads\\agentes_programas\\.venv\\Lib\\site-packages\\langchain\\agents\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "tools = [web_search_urls_fallback]  # el agente SOLO ve la tool orquestadora\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Eres un asistente que encuentra fuentes en la web. Cuando necesites buscar, usa la herramienta y devuelve URLs relevantes.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "resp = executor.invoke({\n",
    "    \"input\": \"Encuentra fuentes oficiales sobre requisitos de visado para colombianos viajando a Japón\"\n",
    "})\n",
    "\n",
    "print(resp[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a10aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Devuelve SIEMPRE un JSON con:\n",
    "{\n",
    " \"question\": \"...\",\n",
    " \"urls\": [\"...\"],\n",
    " \"provider\": \"...\",\n",
    " \"notes\": \"...\"\n",
    "}\n",
    "Si necesitas buscar, usa la herramienta.\"\"\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentes_programas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
